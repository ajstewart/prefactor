#!/usr/bin/env python

import os,sys
import siplib
import feedback
import time
import numpy as np
import get_MOM_data as MOM
import uuid

def input2bool(invar):
    if invar == None:
        return None
    if isinstance(invar, bool):
        return invar
    elif isinstance(invar, str):
        if invar.upper() == 'TRUE' or invar == '1':
            return True
        elif invar.upper() == 'FALSE' or invar == '0':
            return False
        else:
            raise ValueError('input2bool: Cannot convert string "'+invar+'" to boolean!')
    elif isinstance(invar, int) or isinstance(invar, float):
        return bool(invar)
    else:
        raise TypeError('input2bool: Unsupported data type:'+str(type(invar)))

def read_matching_file(matchfile):
    """
    Reads in the match-file generated by sort_times_into_freqGroups.py
    """
    file_matching = {}
    with open(matchfile) as f:
        for line in f:
            parts = line.strip().split()
            file_matching[parts[0]] = parts[1:]
    return file_matching


def get_dataproducts_from_feedback(infile):
    """
    Reads in the pseudo feedback file given as input and returns a list of dataproducts.
    """
    dataproducts = []
    with open(infile) as f:
        text = f.readlines()
        FBdata = feedback.Feedback(text)
        prefix = text[0].split('.')[0]
        dataproducts = FBdata.get_dataproducts(prefix=prefix)
    return dataproducts


def get_pipeline_out_of_my_ass(pipeline_ID, input_dpids,input_dp_source):
    new_pipeline = siplib.CalibrationPipeline(
        siplib.PipelineMap(
            name="prefactor",
            version="2.0",
            sourcedata_identifiers=input_dpids,
            sourcedata_source=input_dp_source,
            process_map=siplib.ProcessMap(
                strategyname="strategy1",
                strategydescription="awesome strategy",
                starttime="1980-03-23T10:20:15",
                duration= "P6Y3M10DT15H",
                observation_source="SAS",
                observation_id="SAS VIC Tree Id",
                process_source="Leiden",
                process_id=pipeline_ID,
                relations=[
                    siplib.ProcessRelation(
                        identifier_source="source",
                        identifier="whyisthismandatory?")],
                parset_source=None,
                parset_id=None
            )
        ),
        skymodeldatabase='prefactor Scaife&Heald',
        numberofinstrumentmodels=1,
        numberofcorrelateddataproducts=0,
        frequencyintegrationstep=None,
        timeintegrationstep=None,
        flagautocorrelations=None,
        demixing=None
    )
    return new_pipeline


def get_LTA_frequency_in_Hz(LTAfreq):
    frequency = LTAfreq.value()
    if LTAfreq.units == 'kHz':
        frequency *= 1000.
    elif LTAfreq.units == 'MHz':
        frequency *= 1e6
    return frequency

def get_LTA_Time_in_s(LTAtime):
    timelength = LTAtime.value()
    if LTAtime.units == 'ms':
        timelength /= 1e3
    elif LTAtime.units == 'us':
        timelength /= 1e6
    elif LTAtime.units == 'ns':
        timelength /= 1e9
    return timelength

def main(matchfile, results_feedback, verbose = False, fail_on_error = True):
    """
    Generate SIP files for all files mentioned in "results_feedback"
    The corresponding input files are taken from "matchfile"

    matchfile : str , path
      Path to the match-file generated by sort_times_into_freqGroups.py 
    results_feedback : str , path
      Path to the feedback file for the pipeline results, generated by the 
      get_metadata recipe.
    verbose : bool, (str with bool value)
      Print more output.
    fail_on_error : bool, (str with bool value)
      Stop processing if a recoverable error occurs in one file.
    """
    file_matching = read_matching_file(matchfile)
    pipeline_products = get_dataproducts_from_feedback(results_feedback)
    verbose = input2bool(verbose)
    fail_on_error = input2bool(fail_on_error)
    for product in pipeline_products:
        product_name = product.get_pyxb_dataproduct().fileName
        if product_name not in file_matching:
            print "make_results_SIP: Could not find file \"%s\" in matching list."%(product_name)
            if fail_on_error:
                raise ValueError("make_results_SIP: Could not find a file in matching list")
            else:
                continue
        # generate IDs for the objects we are going to create new
        product_ID = "data"+str(uuid.uuid4())
        pipeline_ID = "pipe"+str(uuid.uuid4())
        product.set_identifier('prefactor_test',product_ID)
        product.set_process_identifier('prefactor_test',pipeline_ID)
        # Take the SIP of the first input file and fill in needed values
        mom_sip = MOM.get_SIP_from_MSfile(file_matching[product_name][0], verbose=verbose)
        product.set_subarraypointing_identifier(
            mom_sip.sip.dataProduct.subArrayPointingIdentifier.source,
            mom_sip.sip.dataProduct.subArrayPointingIdentifier.identifier
        )
        newsip = siplib.Sip(
            project_code=mom_sip.sip.project.projectCode,
            project_primaryinvestigator=mom_sip.sip.project.primaryInvestigator,
            project_contactauthor=mom_sip.sip.project.contactAuthor,
            #project_telescope="LOFAR",
            project_description=mom_sip.sip.project.projectDescription,
            project_coinvestigators=mom_sip.sip.project.coInvestigator,
            dataproduct = product
        )
        # the following a) doesn't work and b) doesn't seem to be neccessary because
        # the obsevation is included in the SIPs we add
        #newsip.add_observation(mom_sip.sip.observation[0])
        newsip.add_related_dataproduct_with_history(mom_sip)
        input_dpids = [ mom_sip.sip.dataProduct.dataProductIdentifier.identifier ]
        input_dp_source = mom_sip.sip.dataProduct.dataProductIdentifier.source
        for input in file_matching[product_name][1:]:
            mom_sip = MOM.get_SIP_from_MSfile(input, verbose=verbose)
            newsip.add_related_dataproduct_with_history(mom_sip)
            input_dpids.append( mom_sip.sip.dataProduct.dataProductIdentifier.identifier )
        # Compute values for the pipeline definition
        input_chan = get_LTA_frequency_in_Hz(mom_sip.sip.dataProduct.channelWidth)
        output_chan = get_LTA_frequency_in_Hz(product.get_pyxb_dataproduct().channelWidth)
        freqstep = int(np.round(output_chan/input_chan))
        input_int =  get_LTA_Time_in_s(mom_sip.sip.dataProduct.integrationInterval)
        output_int = get_LTA_Time_in_s(product.get_pyxb_dataproduct().integrationInterval)
        timestep = int(np.round(output_int/input_int))
        new_pipeline = get_pipeline_out_of_my_ass(pipeline_ID,input_dpids,input_dp_source)
        newsip.add_pipelinerun(new_pipeline )
        
        print "Length of \"prettyxml\": %d"%( len(newsip.get_prettyxml()) )
        newsip.save_to_file('example-sip.xml')
        if verbose:
            import visualizer
            visualizer.visualize_sip(newsip, path="example-sip.visualization")
    return newsip


if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='Generate the SIP-files for the result MSs from Pre_Facet_Cal.')

    parser.add_argument('ResultsFeedback', type=str, 
                        help='"Pseudo feedback file for the result MSs. One SIP file will be generated for '
                        'each dataproduct in this file.')
    parser.add_argument('Matchfile', type=str,                         
                        help='File matching the pipeline results to the input files. '
                        'Usually generated by \"sort_times_into_freqGroups.py\".')
    parser.add_argument('--cache_file', type=str,
                        default='/media/scratch/test/horneff/Pipeline-Test/feedback_test/sip_cache.pkl',
                        help='File that stores the already-downloaded SIPs. (Will be updated if more SIPs are downloaded.)')
                        

    args = parser.parse_args()

    MOM.init_cache(args.cache_file)
    
    results_file = args.ResultsFeedback
    match_file = args.Matchfile

    main(match_file, results_file, verbose = True, fail_on_error = False)
